from openai import OpenAI
from lib.prompting.prompts import create_operational_countries_prompt, create_news_x_stock_impact_prompt, create_reason_and_impact_prompt


def model_api_client() -> object:
    """Returns an instance of the OpenAI API client."""
    return OpenAI(
        api_key="KG6Dqaqx2APgaNYbqOCrRI5aBXitjbvO",
        base_url="https://api.lemonfox.ai/v1",
    )


def prompt_llm(client: object, prompt: str = "", role: str = "", temperature: int = 0.3) -> str:
    """Interacts with the LLM model to generate a response given the
    prompt and fillers.

    This function uses the OpenAI API client to interact with the LLM model.
    It sends a chat completion request to the model with a system message and a user message.
    The system message contains the role of the user and the user message is generated by filling the prompt with the provided fillers.
    The model then generates a response based on these messages.

    Args:
        client (object): An instance of the OpenAI API client.
        prompt (str): The prompt to be used for generating the response. This is a string that contains placeholders for the fillers.
        role (str): The role of the user. This is used in the system message sent to the model.
        temperature (int): The temperature parameter for the model. This controls the randomness of the generated response.

    Returns:
        str: The generated response from the LLM model.
    """
    return client.chat.completions.create(
        messages=[
            {"role": "system", "content": f"{role}"},
            {"role": "user", "content": f"{prompt}"},
        ],
        model="mixtral-chat",
        temperature=temperature,
    )

def make_impact_from_news(news_content, company_name, stock_position) -> str:
    """ Return either "positive" or "negative" for impact """
    client = model_api_client()

    fillers={
        'news_content': news_content,
        'position': stock_position,
        'company_name': company_name
    }

    prompt = create_news_x_stock_impact_prompt(fillers)

    # try LLM prompt 5 times before giving up
    trials = 0
    correct = False
    impact = "undetermined"
    while (trials < 4) and not correct:
        result = prompt_llm(client, prompt=prompt, role='').choices[0].message.content
        if result.lower()[0:8] == "positive":
            correct = True
            impact = "positive"
        elif result.lower()[0:8] == "negative":
            correct = True
            impact = "negative"
        trials = trials + 1
    return impact

    