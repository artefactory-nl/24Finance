{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! sh ../bin/install_requirements_databricks.sh\n",
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "repo_path = os.path.abspath(os.path.join(cwd, '..'))\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.append(repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb as db \n",
    "import pandas as pd\n",
    "from langchain_chroma import Chroma\n",
    "import tomli\n",
    "\n",
    "from lib.vector.structure import build_vector_db_structure\n",
    "from lib.scraping.scrap import collect_rss_feed, extract_news_content_from_url_to_dataframe, load_rss_urls_from_config\n",
    "from lib.embedding.custom_embedding import CustomHuggingFaceEmbeddings\n",
    "from lib.text_processing.splitting import split_text_into_chunks\n",
    "from lib.utils import convert_to_cet_timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.path.dirname(os.path.abspath(\"\")), \"config\", \"config.toml\"), \"rb\") as f:\n",
    "    config = tomli.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_RSS = config['general']['READ_RSS']     \n",
    "SCRAP_ARTICLES_CONTENT = config['general']['SCRAP_ARTICLES_CONTENT']\n",
    "UPDATE = config['general']['UPDATE_STOCKS_DB']\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 300\n",
    "collection_name = config['data']['vector_db']['news']['news_collection_name']\n",
    "id_column = \"ID\"\n",
    "to_be_embedded_column = \"Content\"\n",
    "metadatas_cols = ['ArticleID','ArticleChunkID','Published','Link','Title','Source','Summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if READ_RSS:\n",
    "    rss_urls = load_rss_urls_from_config(os.path.join(repo_path, 'config', 'rss_urls.yaml'))\n",
    "    rss_feed_df = collect_rss_feed(rss_urls)\n",
    "    rss_feed_df.to_csv(os.path.join(repo_path, config[\"data\"][\"location\"], config[\"data\"][\"rss_feed\"]['location'], config[\"data\"][\"rss_feed\"]['filename']), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SCRAP_ARTICLES_CONTENT:\n",
    "    rss_feed_df = pd.read_csv(os.path.join(repo_path, 'data', 'rss_feed', 'rss_feed_df.csv'))\n",
    "    rss_feed_df = extract_news_content_from_url_to_dataframe(rss_feed_df, url_column = 'Link', output_column = to_be_embedded_column)\n",
    "    rss_feed_df.to_csv(os.path.join(repo_path, config[\"data\"][\"location\"], config[\"data\"][\"rss_feed_with_content\"]['location'], config[\"data\"][\"rss_feed_with_content\"]['filename']), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = CustomHuggingFaceEmbeddings(model_name=config['models']['embdelling_model_name'])  # sentence-transformers/all-MiniLM-l6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_db_path = os.path.join(os.path.dirname(os.path.abspath(\"\")), config[\"data\"][\"location\"], config[\"data\"]['vector_db'][\"location\"],config[\"data\"]['vector_db'][\"news\"][\"location\"])\n",
    "news_chroma_client = db.PersistentClient(path=news_db_path)\n",
    "\n",
    "if collection_name not in [c.name for c in news_chroma_client.list_collections()]:\n",
    "    news_chroma_client.create_collection(\n",
    "        name=collection_name,\n",
    "        metadata={\"hnsw:space\": \"cosine\"},\n",
    "        embedding_function=embedding_model,\n",
    "    )\n",
    "    collection_one = news_chroma_client.get_collection(name=collection_name, embedding_function=embedding_model,)\n",
    "    news_data = pd.read_csv(os.path.join(repo_path, config[\"data\"][\"location\"], config[\"data\"][\"news\"]['rss_feed_with_content']['location'], config[\"data\"][\"news\"]['rss_feed_with_content']['filename']))\n",
    "    news_data = news_data.dropna().reset_index(drop=True).drop_duplicates().reset_index().rename(columns={'index': 'ArticleID'})\n",
    "    news_data['Published'] = news_data['Published'].apply(convert_to_cet_timezone)\n",
    "    news_data = split_text_into_chunks(news_data, content_col=to_be_embedded_column, chunk_size= chunk_size, chunk_overlap=chunk_overlap, separator= \" \", chunk_colname='ArticleChunkID')\n",
    "    vect_db_structure = build_vector_db_structure(news_data, metadatas_cols, id_column, to_be_embedded_column)\n",
    "    collection_one.add(\n",
    "        documents=vect_db_structure['datas'],\n",
    "        metadatas=vect_db_structure['metadatas'],\n",
    "        ids=vect_db_structure['ids']\n",
    "    )\n",
    "else:\n",
    "    if UPDATE==True:\n",
    "        collection_one = news_chroma_client.get_collection(name=collection_name, embedding_function=embedding_model)\n",
    "        news_data = pd.read_csv(os.path.join(repo_path, config[\"data\"][\"location\"], config[\"data\"][\"news\"]['rss_feed_with_content']['location'], config[\"data\"][\"news\"]['rss_feed_with_content']['filename']))\n",
    "        news_data = news_data.dropna().reset_index(drop=True).drop_duplicates().reset_index().rename(columns={'index': 'ArticleID'})\n",
    "        news_data['Published'] = news_data['Published'].apply(convert_to_cet_timezone)\n",
    "        news_data = split_text_into_chunks(news_data, content_col=to_be_embedded_column, chunk_size= chunk_size, chunk_overlap=chunk_overlap, separator= \" \", chunk_colname='ArticleChunkID')\n",
    "        news_data[id_column] = news_data[id_column] + max([int(id) for id in collection_one.get()['ids']])\n",
    "        vect_db_structure = build_vector_db_structure(news_data, metadatas_cols, id_column, to_be_embedded_column)\n",
    "        collection_one.add(\n",
    "            documents=vect_db_structure['datas'],\n",
    "            metadatas=vect_db_structure['metadatas'],\n",
    "            ids=vect_db_structure['ids']\n",
    "        )\n",
    "    else:\n",
    "        collection_one = news_chroma_client.get_collection(name=collection_name, embedding_function=embedding_model,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_chroma = Chroma(\n",
    "    client=news_chroma_client,\n",
    "    collection_name=collection_name,\n",
    "    embedding_function=embedding_model,\n",
    ")\n",
    "print(\"There are\", langchain_chroma._collection.count(), \"in the collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of querying the collection\n",
    "client = db.PersistentClient(path=news_db_path)\n",
    "collection = client.get_collection(name=collection_name, embedding_function=embedding_model)\n",
    "collection.query(query_embeddings=embedding_model.embed_query(\"oil\"), n_results=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artefact-hackathon-team-04",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
